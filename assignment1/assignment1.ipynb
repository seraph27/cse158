{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "for l in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    allRatings.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsTrain = allRatings[:190000]\n",
    "ratingsValid = allRatings[190000:]\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "bookPerUser = defaultdict(list)\n",
    "userPerBook = defaultdict(list)\n",
    "for u,b,r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))\n",
    "    bookPerUser[u].append(b)\n",
    "    userPerBook[b].append(u)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    return len(s1.intersection(s2)) / len(s1.union(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "allbooks = set()\n",
    "for _, book, _ in allRatings:\n",
    "    allbooks.add(book)\n",
    "allbooks = list(allbooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsValidBinary = [(user, book, 1) for user, book, _ in ratingsValid]\n",
    "for user, book, _ in ratingsValid:\n",
    "    newBook = random.choice(allbooks)\n",
    "    while newBook in [b for b, _ in ratingsPerUser[user]]:\n",
    "        newBook = random.choice(allbooks)\n",
    "    ratingsValidBinary.append((user, newBook, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(ratingsValidBinary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 b70000668\n",
      "0.7492\n",
      "Popularity model:  0.7492\n"
     ]
    }
   ],
   "source": [
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "threshold = 0.7085\n",
    "\n",
    "for _ ,book,_ in ratingsTrain:\n",
    "    bookCount[book] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "count = 0\n",
    "popular = set()\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    popular.add(i)\n",
    "    if count > totalRead * threshold: \n",
    "        print(ic, i)\n",
    "        break\n",
    "\n",
    "correct = 0\n",
    "for _, book, predict in ratingsValidBinary:\n",
    "    correct += predict == (book in popular)\n",
    "\n",
    "acc1 = correct / len(ratingsValidBinary)\n",
    "print(acc1)\n",
    "\n",
    "print(\"Popularity model: \", acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to beat 75.68% //32 read is the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined(thresh1, thresh2):\n",
    "    ans = {}\n",
    "    max_popularity = max(len(ratingsPerItem[b]) for b in ratingsPerItem)\n",
    "    for user, book, _ in ratingsValidBinary:\n",
    "        users_for_book = set(u for u, _ in ratingsPerItem[book])\n",
    "        bprime = set(b for b, _ in ratingsPerUser[user] if b != book)\n",
    "        \n",
    "        maxjaccard = 0\n",
    "        for b in bprime:\n",
    "            jac = Jaccard(set(u for u, _ in ratingsPerItem[b]), users_for_book)\n",
    "            maxjaccard = max(maxjaccard, jac)\n",
    "        #popularity_score = len(users_for_book) / max_popularity\n",
    "\n",
    "        if maxjaccard > thresh1 and bookCount[book] > thresh2:\n",
    "            ans[(user, book)] = 1\n",
    "        else:\n",
    "            ans[(user, book)] = 0\n",
    "\n",
    "\n",
    "    correct = sum(1 for user, book, r in ratingsValidBinary if ans.get((user, book)) == r)\n",
    "    accuracy = correct / len(ratingsValidBinary) if ratingsValidBinary else 0\n",
    "\n",
    "    one, zero = 0, 0\n",
    "    for val in ans.values():\n",
    "        if val: one += 1\n",
    "        else: zero += 1\n",
    "\n",
    "    print(\"One: \", one)\n",
    "    print(\"Zero: \", zero)\n",
    "\n",
    "\n",
    "    TP, FP, TN, FN = 0, 0, 0, 0\n",
    "    for user, book, r in ratingsValidBinary:\n",
    "        if ans.get((user, book)): # if 1\n",
    "            if r == 1:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "        else:\n",
    "            if r == 1:\n",
    "                FN += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "    print(\"TP: \", TP)\n",
    "    print(\"FP: \", FP)\n",
    "    print(\"TN: \", TN)\n",
    "    print(\"FN: \", FN)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One:  6096\n",
      "Zero:  13903\n",
      "TP:  5203\n",
      "FP:  893\n",
      "TN:  9107\n",
      "FN:  4797\n",
      "One:  4569\n",
      "Zero:  15430\n",
      "TP:  4010\n",
      "FP:  559\n",
      "TN:  9441\n",
      "FN:  5990\n",
      "One:  4796\n",
      "Zero:  15203\n",
      "TP:  4037\n",
      "FP:  759\n",
      "TN:  9241\n",
      "FN:  5963\n",
      "One:  7209\n",
      "Zero:  12790\n",
      "TP:  5898\n",
      "FP:  1311\n",
      "TN:  8689\n",
      "FN:  4102\n",
      "One:  6016\n",
      "Zero:  13983\n",
      "TP:  5163\n",
      "FP:  853\n",
      "TN:  9147\n",
      "FN:  4837\n",
      "One:  5783\n",
      "Zero:  14216\n",
      "TP:  4762\n",
      "FP:  1021\n",
      "TN:  8979\n",
      "FN:  5238\n",
      "One:  5519\n",
      "Zero:  14480\n",
      "TP:  4743\n",
      "FP:  776\n",
      "TN:  9224\n",
      "FN:  5257\n",
      "One:  7183\n",
      "Zero:  12816\n",
      "TP:  5870\n",
      "FP:  1313\n",
      "TN:  8687\n",
      "FN:  4130\n",
      "One:  2384\n",
      "Zero:  17615\n",
      "TP:  2144\n",
      "FP:  240\n",
      "TN:  9760\n",
      "FN:  7856\n",
      "One:  8932\n",
      "Zero:  11067\n",
      "TP:  6874\n",
      "FP:  2058\n",
      "TN:  7942\n",
      "FN:  3126\n",
      "One:  9294\n",
      "Zero:  10705\n",
      "TP:  7049\n",
      "FP:  2245\n",
      "TN:  7755\n",
      "FN:  2951\n",
      "One:  5699\n",
      "Zero:  14300\n",
      "TP:  4938\n",
      "FP:  761\n",
      "TN:  9239\n",
      "FN:  5062\n",
      "One:  8726\n",
      "Zero:  11273\n",
      "TP:  6726\n",
      "FP:  2000\n",
      "TN:  8000\n",
      "FN:  3274\n",
      "One:  9294\n",
      "Zero:  10705\n",
      "TP:  7049\n",
      "FP:  2245\n",
      "TN:  7755\n",
      "FN:  2951\n",
      "One:  7572\n",
      "Zero:  12427\n",
      "TP:  6188\n",
      "FP:  1384\n",
      "TN:  8616\n",
      "FN:  3812\n",
      "One:  8410\n",
      "Zero:  11589\n",
      "TP:  6621\n",
      "FP:  1789\n",
      "TN:  8211\n",
      "FN:  3379\n",
      "One:  3318\n",
      "Zero:  16681\n",
      "TP:  2727\n",
      "FP:  591\n",
      "TN:  9409\n",
      "FN:  7273\n",
      "One:  7556\n",
      "Zero:  12443\n",
      "TP:  6177\n",
      "FP:  1379\n",
      "TN:  8621\n",
      "FN:  3823\n",
      "One:  8357\n",
      "Zero:  11642\n",
      "TP:  6592\n",
      "FP:  1765\n",
      "TN:  8235\n",
      "FN:  3408\n",
      "One:  8357\n",
      "Zero:  11642\n",
      "TP:  6592\n",
      "FP:  1765\n",
      "TN:  8235\n",
      "FN:  3408\n",
      "One:  8357\n",
      "Zero:  11642\n",
      "TP:  6592\n",
      "FP:  1765\n",
      "TN:  8235\n",
      "FN:  3408\n",
      "One:  8357\n",
      "Zero:  11642\n",
      "TP:  6592\n",
      "FP:  1765\n",
      "TN:  8235\n",
      "FN:  3408\n",
      "One:  7513\n",
      "Zero:  12486\n",
      "TP:  5953\n",
      "FP:  1560\n",
      "TN:  8440\n",
      "FN:  4047\n",
      "One:  8410\n",
      "Zero:  11589\n",
      "TP:  6621\n",
      "FP:  1789\n",
      "TN:  8211\n",
      "FN:  3379\n",
      "One:  6712\n",
      "Zero:  13287\n",
      "TP:  5650\n",
      "FP:  1062\n",
      "TN:  8938\n",
      "FN:  4350\n",
      "One:  9294\n",
      "Zero:  10705\n",
      "TP:  7049\n",
      "FP:  2245\n",
      "TN:  7755\n",
      "FN:  2951\n",
      "One:  5348\n",
      "Zero:  14651\n",
      "TP:  4657\n",
      "FP:  691\n",
      "TN:  9309\n",
      "FN:  5343\n",
      "One:  8138\n",
      "Zero:  11861\n",
      "TP:  6464\n",
      "FP:  1674\n",
      "TN:  8326\n",
      "FN:  3536\n",
      "One:  8410\n",
      "Zero:  11589\n",
      "TP:  6621\n",
      "FP:  1789\n",
      "TN:  8211\n",
      "FN:  3379\n",
      "One:  6864\n",
      "Zero:  13135\n",
      "TP:  5740\n",
      "FP:  1124\n",
      "TN:  8876\n",
      "FN:  4260\n",
      "One:  8410\n",
      "Zero:  11589\n",
      "TP:  6621\n",
      "FP:  1789\n",
      "TN:  8211\n",
      "FN:  3379\n",
      "One:  2508\n",
      "Zero:  17491\n",
      "TP:  2221\n",
      "FP:  287\n",
      "TN:  9713\n",
      "FN:  7779\n",
      "One:  8479\n",
      "Zero:  11520\n",
      "TP:  6656\n",
      "FP:  1823\n",
      "TN:  8177\n",
      "FN:  3344\n",
      "One:  6166\n",
      "Zero:  13833\n",
      "TP:  5276\n",
      "FP:  890\n",
      "TN:  9110\n",
      "FN:  4724\n",
      "One:  9223\n",
      "Zero:  10776\n",
      "TP:  7006\n",
      "FP:  2217\n",
      "TN:  7783\n",
      "FN:  2994\n",
      "One:  7961\n",
      "Zero:  12038\n",
      "TP:  6297\n",
      "FP:  1664\n",
      "TN:  8336\n",
      "FN:  3703\n",
      "One:  9294\n",
      "Zero:  10705\n",
      "TP:  7049\n",
      "FP:  2245\n",
      "TN:  7755\n",
      "FN:  2951\n",
      "One:  8410\n",
      "Zero:  11589\n",
      "TP:  6621\n",
      "FP:  1789\n",
      "TN:  8211\n",
      "FN:  3379\n",
      "One:  8410\n",
      "Zero:  11589\n",
      "TP:  6621\n",
      "FP:  1789\n",
      "TN:  8211\n",
      "FN:  3379\n",
      "One:  7919\n",
      "Zero:  12080\n",
      "TP:  6368\n",
      "FP:  1551\n",
      "TN:  8449\n",
      "FN:  3632\n",
      "One:  8410\n",
      "Zero:  11589\n",
      "TP:  6621\n",
      "FP:  1789\n",
      "TN:  8211\n",
      "FN:  3379\n",
      "One:  8051\n",
      "Zero:  11948\n",
      "TP:  6428\n",
      "FP:  1623\n",
      "TN:  8377\n",
      "FN:  3572\n",
      "One:  8410\n",
      "Zero:  11589\n",
      "TP:  6621\n",
      "FP:  1789\n",
      "TN:  8211\n",
      "FN:  3379\n",
      "One:  8357\n",
      "Zero:  11642\n",
      "TP:  6592\n",
      "FP:  1765\n",
      "TN:  8235\n",
      "FN:  3408\n",
      "One:  8410\n",
      "Zero:  11589\n",
      "TP:  6621\n",
      "FP:  1789\n",
      "TN:  8211\n",
      "FN:  3379\n",
      "One:  9042\n",
      "Zero:  10957\n",
      "TP:  6905\n",
      "FP:  2137\n",
      "TN:  7863\n",
      "FN:  3095\n",
      "One:  8357\n",
      "Zero:  11642\n",
      "TP:  6592\n",
      "FP:  1765\n",
      "TN:  8235\n",
      "FN:  3408\n",
      "One:  4196\n",
      "Zero:  15803\n",
      "TP:  3643\n",
      "FP:  553\n",
      "TN:  9447\n",
      "FN:  6357\n",
      "One:  6211\n",
      "Zero:  13788\n",
      "TP:  5310\n",
      "FP:  901\n",
      "TN:  9099\n",
      "FN:  4690\n",
      "One:  6261\n",
      "Zero:  13738\n",
      "TP:  5342\n",
      "FP:  919\n",
      "TN:  9081\n",
      "FN:  4658\n",
      "Optimal Thresholds:  [0.0005784272252330343, np.int64(28)]\n",
      "Optimal Accuracy:  0.74165\n"
     ]
    }
   ],
   "source": [
    "#print(combined(0.0088, 37))\n",
    "from skopt import gp_minimize\n",
    "\n",
    "def objective(params):\n",
    "    t1, t2 = params\n",
    "    return -combined(t1, int(t2))  # Negative because we minimize\n",
    "\n",
    "res = gp_minimize(objective, [(0, 0.01), (20, 75)], n_calls=50)\n",
    "print(\"Optimal Thresholds: \", res.x)\n",
    "print(\"Optimal Accuracy: \", -res.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.2.7-cp310-cp310-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting graphviz (from catboost)\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\seraph\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (3.9.2)\n",
      "Collecting numpy<2.0,>=1.16.0 (from catboost)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\seraph\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (2.2.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\seraph\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (1.14.1)\n",
      "Collecting plotly (from catboost)\n",
      "  Downloading plotly-5.24.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: six in c:\\users\\seraph\\appdata\\roaming\\python\\python310\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\seraph\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\seraph\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\seraph\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\seraph\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\seraph\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\seraph\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\seraph\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\seraph\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\seraph\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\seraph\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (3.1.4)\n",
      "Collecting tenacity>=6.2.0 (from plotly->catboost)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Downloading catboost-1.2.7-cp310-cp310-win_amd64.whl (101.8 MB)\n",
      "   ---------------------------------------- 0.0/101.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.6/101.8 MB 8.4 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 3.4/101.8 MB 8.0 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 5.0/101.8 MB 7.9 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 6.8/101.8 MB 7.9 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 8.4/101.8 MB 8.0 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 10.2/101.8 MB 8.0 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 12.1/101.8 MB 8.0 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 13.6/101.8 MB 8.0 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 15.2/101.8 MB 8.0 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 17.0/101.8 MB 8.1 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 18.9/101.8 MB 8.1 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 20.4/101.8 MB 8.1 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 22.3/101.8 MB 8.1 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 24.1/101.8 MB 8.1 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 25.7/101.8 MB 8.1 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 27.5/101.8 MB 8.2 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 29.4/101.8 MB 8.1 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 30.9/101.8 MB 8.1 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 32.2/101.8 MB 8.1 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 33.8/101.8 MB 8.0 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 35.7/101.8 MB 8.1 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 37.5/101.8 MB 8.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 39.1/101.8 MB 8.1 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 40.9/101.8 MB 8.1 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 42.5/101.8 MB 8.0 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 44.3/101.8 MB 8.1 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 45.9/101.8 MB 8.0 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 47.4/101.8 MB 8.0 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 49.3/101.8 MB 8.0 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 50.9/101.8 MB 8.0 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 52.4/101.8 MB 8.0 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 54.0/101.8 MB 8.0 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 55.8/101.8 MB 8.0 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 57.4/101.8 MB 8.0 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 59.2/101.8 MB 7.9 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 60.8/101.8 MB 7.9 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 62.7/101.8 MB 7.9 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 64.2/101.8 MB 7.9 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 65.8/101.8 MB 7.9 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 67.4/101.8 MB 7.9 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 68.9/101.8 MB 7.9 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 70.8/101.8 MB 7.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 72.4/101.8 MB 7.9 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 74.2/101.8 MB 7.9 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 75.8/101.8 MB 7.9 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 77.3/101.8 MB 7.9 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 79.2/101.8 MB 7.9 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 80.7/101.8 MB 7.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 82.6/101.8 MB 7.9 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 84.1/101.8 MB 7.9 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 86.0/101.8 MB 7.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 87.6/101.8 MB 7.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 89.4/101.8 MB 7.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 91.2/101.8 MB 7.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 92.8/101.8 MB 7.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 94.6/101.8 MB 7.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 96.2/101.8 MB 7.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 98.0/101.8 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.6/101.8 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.4/101.8 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 101.8/101.8 MB 7.8 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.6/15.8 MB 8.3 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.4/15.8 MB 8.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.7/15.8 MB 7.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.6/15.8 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.9/15.8 MB 7.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.7/15.8 MB 7.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 11.0/15.8 MB 7.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.8 MB 7.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.7/15.8 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 7.8 MB/s eta 0:00:00\n",
      "Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "Downloading plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
      "   ---------------------------------------- 0.0/19.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.6/19.1 MB 8.3 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 3.4/19.1 MB 8.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 5.0/19.1 MB 8.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 6.8/19.1 MB 8.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 8.4/19.1 MB 8.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 10.2/19.1 MB 8.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 12.1/19.1 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 13.6/19.1 MB 8.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 15.5/19.1 MB 8.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 17.0/19.1 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  18.9/19.1 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.1/19.1 MB 8.0 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: tenacity, numpy, graphviz, plotly, catboost\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.2\n",
      "    Uninstalling numpy-2.1.2:\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "Successfully installed catboost-1.2.7 graphviz-0.20.3 numpy-1.26.4 plotly-5.24.1 tenacity-9.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Seraph\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Seraph\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "combined(0.0022, 23)\n",
    "One:  8537\n",
    "Zero:  11460\n",
    "TP:  6673\n",
    "FP:  3327\n",
    "TN:  8135\n",
    "FN:  1865\n",
    "0.7404\n",
    "\n",
    "print(combined(0.0088, 37))\n",
    "One:  9958\n",
    "Zero:  10039\n",
    "TP:  7457\n",
    "FP:  2502\n",
    "TN:  7498\n",
    "FN:  2543\n",
    "0.74775\n",
    "\n",
    "Optimal Thresholds:  [0.02642941668361511, np.int64(33)]\n",
    "Optimal Accuracy:  0.7511\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  5829\n",
      "FP:  4171\n",
      "TN:  8805\n",
      "FN:  1195\n",
      "Threshold: 0.035, Accuracy: 0.7317\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m thresh_range \u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0.035\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.005\u001b[39m)  \u001b[38;5;66;03m# Example: 0.0, 0.1, 0.2, ..., 1.0\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Run grid search\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m best_thresh1, best_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search_threshold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthresh_range\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_thresh1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Best Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[108], line 6\u001b[0m, in \u001b[0;36mgrid_search_threshold\u001b[1;34m(thresh_range)\u001b[0m\n\u001b[0;32m      3\u001b[0m best_thresh1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m thresh1 \u001b[38;5;129;01min\u001b[39;00m thresh_range:\n\u001b[1;32m----> 6\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mcombined\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthresh1\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calculate accuracy for the current threshold\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThreshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthresh1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accuracy \u001b[38;5;241m>\u001b[39m best_accuracy:\n",
      "Cell \u001b[1;32mIn[107], line 10\u001b[0m, in \u001b[0;36mcombined\u001b[1;34m(thresh1)\u001b[0m\n\u001b[0;32m      8\u001b[0m maxjaccard \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bprime:\n\u001b[1;32m---> 10\u001b[0m     jac \u001b[38;5;241m=\u001b[39m Jaccard(\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mratingsPerItem\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, users_for_book)\n\u001b[0;32m     11\u001b[0m     maxjaccard \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(maxjaccard, jac)\n\u001b[0;32m     12\u001b[0m popularity_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(users_for_book) \u001b[38;5;241m/\u001b[39m max_popularity\n",
      "Cell \u001b[1;32mIn[107], line 10\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      8\u001b[0m maxjaccard \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bprime:\n\u001b[1;32m---> 10\u001b[0m     jac \u001b[38;5;241m=\u001b[39m Jaccard(\u001b[38;5;28mset\u001b[39m(u \u001b[38;5;28;01mfor\u001b[39;00m u, _ \u001b[38;5;129;01min\u001b[39;00m ratingsPerItem[b]), users_for_book)\n\u001b[0;32m     11\u001b[0m     maxjaccard \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(maxjaccard, jac)\n\u001b[0;32m     12\u001b[0m popularity_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(users_for_book) \u001b[38;5;241m/\u001b[39m max_popularity\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Finding optimal thresholds\n",
    "best_accuracy = 0\n",
    "optimal_thresh1 = 0\n",
    "optimal_thresh2 = 0\n",
    "\n",
    "# Testing thresholds in range\n",
    "thresh1_range = np.linspace(0, 1, 10)  # Adjust granularity as needed\n",
    "thresh2_range = range(1, max(bookCount.values()) + 1)\n",
    "\n",
    "for t1 in thresh1_range:\n",
    "    for t2 in thresh2_range:\n",
    "        acc = combined(t1, t2)\n",
    "        if acc > best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            optimal_thresh1 = t1\n",
    "            optimal_thresh2 = t2\n",
    "\n",
    "optimal_thresh1, optimal_thresh2, best_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6052\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "max_popularity = max(len(ratingsPerItem[b]) for b in ratingsPerItem)\n",
    "\n",
    "def extract_features(user, book):\n",
    "    users_for_book = set(u for u, _ in ratingsPerItem[book])\n",
    "    bprime = set(b for b, _ in ratingsPerUser[user] if b != book)\n",
    "    jaccard_similarities = [Jaccard(users_for_book, set(u for u, _ in ratingsPerItem[b])) for b in bprime] if bprime else [0]\n",
    "    \n",
    "    # Jaccard-based features\n",
    "    max_jaccard = max(jaccard_similarities)\n",
    "    mean_jaccard = np.mean(jaccard_similarities)\n",
    "    count_high_jaccard = sum(1 for j in jaccard_similarities if j > 0.5)\n",
    "    \n",
    "    # Popularity-based features\n",
    "    popularity_score = len(users_for_book) / max_popularity\n",
    "    user_popularity_avg = np.mean([len(set(u for u, _ in ratingsPerItem[b])) / max_popularity for b, _ in ratingsPerUser[user]])\n",
    "    \n",
    "    # User-specific feature\n",
    "    user_total_books = len(ratingsPerUser[user])\n",
    "    \n",
    "    return [max_jaccard, mean_jaccard, count_high_jaccard, popularity_score, user_popularity_avg, user_total_books]\n",
    "\n",
    "features = [extract_features(user, book) for user, book, _ in ratingsTrainBinary]\n",
    "labels = [predict for _, _, predict in ratingsTrainBinary]\n",
    "\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "clf.fit(features, labels)\n",
    "\n",
    "\n",
    "features_valid = [extract_features(user, book) for user, book, _ in ratingsValidBinary]\n",
    "labels_valid = [predict for _, _, predict in ratingsValidBinary]\n",
    "\n",
    "\n",
    "features_valid = np.array(features_valid)\n",
    "labels_valid = np.array(labels_valid)\n",
    "\n",
    "features_valid = scaler.transform(features_valid)\n",
    "\n",
    "predictions = clf.predict(features_valid)\n",
    "accuracy = accuracy_score(labels_valid, predictions)\n",
    "print(\"Validation Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x15f50bd29e0>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(labels_valid, predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive jaccard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def solve(thresh1):\n",
    "#     ans = {}\n",
    "#     for user, book, _ in ratingsValidBinary:\n",
    "#         users_for_book = set(u for u, _ in ratingsPerItem[book])\n",
    "#         bprime = set(b for b, _ in ratingsPerUser[user] if b != book)\n",
    "        \n",
    "#         max_jaccard = 0\n",
    "#         for b in bprime:\n",
    "#             jaccard = Jaccard(set(u for u, _ in ratingsPerItem[b]), users_for_book)\n",
    "#             max_jaccard = max(max_jaccard, jaccard)\n",
    "        \n",
    "#         ans[(user, book)] = 1 if max_jaccard > thresh1 else 0\n",
    "\n",
    "#     correct = sum(1 for user, book, r in ratingsValidBinary if ans.get((user, book)) == r)\n",
    "#     accuracy = correct / len(ratingsValidBinary) if ratingsValidBinary else 0\n",
    "#     return accuracy\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69855"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solve(0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weighted jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_books = set() \n",
    "# def solve(alpha, combined_thresh):\n",
    "#     read_books.clear()\n",
    "#     max_popularity = max(len(ratingsPerItem[b]) for b in ratingsPerItem)\n",
    "\n",
    "#     for user, book, _ in ratingsValidBinary:\n",
    "#         users_for_book = set(u for u, _ in ratingsPerItem[book])\n",
    "#         bprime = set(b for b, _ in ratingsPerUser[user] if b != book)\n",
    "        \n",
    "#         max_jaccard = 0\n",
    "#         for b in bprime:\n",
    "#             jaccard = Jaccard(set(u for u, _ in ratingsPerItem[b]), users_for_book)\n",
    "#             max_jaccard = max(max_jaccard, jaccard)\n",
    "             \n",
    "#         popularity_score = len(users_for_book) / max_popularity\n",
    "#         if(len(users_for_book) > 50):\n",
    "#             read_books.add(book)\n",
    "#             continue\n",
    "#         combined_score = alpha * max_jaccard + (1 - alpha) * popularity_score\n",
    "#         if combined_score > combined_thresh:\n",
    "#             read_books.add(book) \n",
    "\n",
    "#     correct = 0\n",
    "#     for _, book, predict in ratingsValidBinary:\n",
    "#         correct += (predict == 1 and book in read_books) or (predict == 0 and book not in read_books)\n",
    "    \n",
    "#     acc = correct / len(ratingsValidBinary)\n",
    "#     return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimal Alpha Threshold: 0.55, Optimal Combined Threshold: 0.02, Best Accuracy: 0.75725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7494\n"
     ]
    }
   ],
   "source": [
    "print(solve(0.1, 0.032))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Threshold: 0.5, Combined Threshold: 0.02, Accuracy: 0.738\n",
      "Alpha Threshold: 0.5, Combined Threshold: 0.021, Accuracy: 0.739\n",
      "Alpha Threshold: 0.5, Combined Threshold: 0.022000000000000002, Accuracy: 0.7413\n",
      "Alpha Threshold: 0.5, Combined Threshold: 0.023000000000000003, Accuracy: 0.742\n",
      "Alpha Threshold: 0.51, Combined Threshold: 0.02, Accuracy: 0.7385\n",
      "Alpha Threshold: 0.51, Combined Threshold: 0.021, Accuracy: 0.7394\n",
      "Alpha Threshold: 0.51, Combined Threshold: 0.022000000000000002, Accuracy: 0.74075\n",
      "Alpha Threshold: 0.51, Combined Threshold: 0.023000000000000003, Accuracy: 0.7416\n",
      "Alpha Threshold: 0.52, Combined Threshold: 0.02, Accuracy: 0.73855\n",
      "Alpha Threshold: 0.52, Combined Threshold: 0.021, Accuracy: 0.73925\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[140], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m alpha_range \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.56\u001b[39m, \u001b[38;5;241m0.01\u001b[39m) \n\u001b[0;32m     18\u001b[0m combined_range \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0.02\u001b[39m, \u001b[38;5;241m0.024\u001b[39m, \u001b[38;5;241m0.001\u001b[39m) \n\u001b[1;32m---> 20\u001b[0m best_alpha_thresh, best_combined_thresh, best_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mgs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_range\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimal Alpha Threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_alpha_thresh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Optimal Combined Threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_combined_thresh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Best Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[140], line 8\u001b[0m, in \u001b[0;36mgs\u001b[1;34m(alpha_range, combined_range)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m alpha_thresh \u001b[38;5;129;01min\u001b[39;00m alpha_range:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m combined_thresh \u001b[38;5;129;01min\u001b[39;00m combined_range:\n\u001b[1;32m----> 8\u001b[0m         accuracy \u001b[38;5;241m=\u001b[39m \u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43malpha_thresh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_thresh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlpha Threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malpha_thresh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Combined Threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcombined_thresh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m accuracy \u001b[38;5;241m>\u001b[39m best_accuracy:\n",
      "Cell \u001b[1;32mIn[134], line 12\u001b[0m, in \u001b[0;36msolve\u001b[1;34m(alpha, combined_thresh)\u001b[0m\n\u001b[0;32m     10\u001b[0m max_jaccard \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bprime:\n\u001b[1;32m---> 12\u001b[0m     jaccard \u001b[38;5;241m=\u001b[39m Jaccard(\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mratingsPerItem\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, users_for_book)\n\u001b[0;32m     13\u001b[0m     max_jaccard \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(max_jaccard, jaccard)\n\u001b[0;32m     15\u001b[0m popularity_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(users_for_book) \u001b[38;5;241m/\u001b[39m max_popularity\n",
      "Cell \u001b[1;32mIn[134], line 12\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     10\u001b[0m max_jaccard \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bprime:\n\u001b[1;32m---> 12\u001b[0m     jaccard \u001b[38;5;241m=\u001b[39m Jaccard(\u001b[38;5;28mset\u001b[39m(u \u001b[38;5;28;01mfor\u001b[39;00m u, _ \u001b[38;5;129;01min\u001b[39;00m ratingsPerItem[b]), users_for_book)\n\u001b[0;32m     13\u001b[0m     max_jaccard \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(max_jaccard, jaccard)\n\u001b[0;32m     15\u001b[0m popularity_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(users_for_book) \u001b[38;5;241m/\u001b[39m max_popularity\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def gs(alpha_range, combined_range):\n",
    "    best_accuracy = 0\n",
    "    best_alpha_thresh = None\n",
    "    best_combined_thresh = None\n",
    "    for alpha_thresh in alpha_range:\n",
    "        for combined_thresh in combined_range:\n",
    "            accuracy = solve(alpha_thresh, combined_thresh)\n",
    "            print(f\"Alpha Threshold: {alpha_thresh}, Combined Threshold: {combined_thresh}, Accuracy: {accuracy}\")\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_alpha_thresh = alpha_thresh\n",
    "                best_combined_thresh = combined_thresh\n",
    "\n",
    "    return best_alpha_thresh, best_combined_thresh, best_accuracy\n",
    "\n",
    "alpha_range = np.arange(0.5, 0.56, 0.01) \n",
    "combined_range = np.arange(0.02, 0.024, 0.001) \n",
    "\n",
    "best_alpha_thresh, best_combined_thresh, best_accuracy = gs(\n",
    "    alpha_range, combined_range\n",
    ")\n",
    "print(f\"Optimal Alpha Threshold: {best_alpha_thresh}, Optimal Combined Threshold: {best_combined_thresh}, Best Accuracy: {best_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimal Alpha Threshold: 0.535, Optimal Combined Threshold: 0.022000000000000002, Best Accuracy: 0.7595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Read.csv\", 'w')\n",
    "for l in open(\"pairs_Read.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split(',')\n",
    "    if b in ret:\n",
    "        predictions.write(u + ',' + b + \",1\\n\")\n",
    "    else:\n",
    "        predictions.write(u + ',' + b + \",0\\n\")\n",
    "\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.mean([r for _, _, r in ratingsTrain])\n",
    "beta_user = defaultdict(float)\n",
    "beta_book = defaultdict(float)\n",
    "\n",
    "def solve(lambda_reg):\n",
    "    for _ in range(100):\n",
    "        alpha = sum(rating - (beta_user[user] + beta_book[book]) for user, book, rating in ratingsTrain) / len(ratingsTrain)\n",
    "        for user, items in ratingsPerUser.items():\n",
    "            beta_user[user] = sum(rating - (alpha + beta_book[book]) for book, rating in items) / (lambda_reg + len(items))\n",
    "        for book, items in ratingsPerItem.items():\n",
    "            beta_book[book] = sum(rating - (alpha + beta_user[user]) for user, rating in items) / (lambda_reg + len(items))\n",
    "\n",
    "    valid_error = [(rating - (alpha + beta_user.get(user, 0) + beta_book.get(book, 0))) ** 2 for user, book, rating in ratingsValid]\n",
    "    validMSE = np.mean(valid_error).item()\n",
    "    return validMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.342360167360211 1.4106621594632809"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.333333333333336 66.66666666666666\n",
      "22.222222222222218 44.44444444444444\n",
      "14.814814814814815 29.629629629629626\n",
      "9.876543209876543 19.75308641975308\n",
      "6.584362139917694 13.168724279835388\n",
      "4.38957475994513 8.779149519890257\n",
      "2.9263831732967525 5.852766346593505\n",
      "4.8773052888279205 6.828227404359089\n",
      "4.226997916984198 5.527612660671644\n",
      "3.793459669088383 4.660536164880013\n",
      "4.371510666282803 4.9495616634772235\n",
      "4.17882700055133 4.564194332014276\n",
      "4.050371223397014 4.307282777705645\n",
      "4.221645592936102 4.3929199624751885\n",
      "4.3358285059621595 4.450011418988218\n",
      "4.297767534953474 4.373889476970846\n",
      "4.348515496298389 4.399263457643303\n",
      "4.331599509183417 4.36543148341336\n",
      "4.320322184440102 4.342876833926732\n",
      "4.335358617431188 4.350395050422274\n",
      "4.3303464731008265 4.34037076176155\n",
      "4.337029332207976 4.343712191315125\n",
      "4.341484571612742 4.345939811017508\n",
      "4.339999491811153 4.342969651414331\n",
      "4.339009438610094 4.340989545012213\n",
      "4.34032950954484 4.341649580479585\n",
      "4.339889485899924 4.3407695331897544\n",
      "4.340476184093144 4.341062882286365\n",
      "4.340280618028737 4.340671750157552\n",
      "4.34054137278128 4.340802127533823\n",
      "4.340454454530432 4.340628291032128\n",
      "4.340396509029867 4.340512400030998\n",
      "4.3404737696972875 4.340551030364708\n",
      "4.340525276808901 4.340576783920515\n",
      "4.340508107771696 4.340542445846106\n"
     ]
    }
   ],
   "source": [
    "l, r, eps = 0, 100, 1e-4\n",
    "\n",
    "while(r-l > eps):\n",
    "    m1 = l + (r-l)/3\n",
    "    m2 = r - (r-l)/3\n",
    "    print(m1, m2)\n",
    "    if solve(m1) < solve(m2):\n",
    "        r = m2\n",
    "    else:\n",
    "        l = m1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.340508107771696"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.410147696254751\n"
     ]
    }
   ],
   "source": [
    "print(solve(4.342282906692791 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Rating.csv\", 'w')\n",
    "for l in open(\"pairs_Rating.csv\"):\n",
    "    if l.startswith(\"userID\"): # header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split(',') # Read the user and item from the \"pairs\" file and write out your prediction\n",
    "    prediction = alpha + beta_user.get(u, 0) + beta_book.get(b, 0)\n",
    "    predictions.write(u + ',' + b + ',' + str(prediction) + '\\n')\n",
    "    \n",
    "predictions.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
