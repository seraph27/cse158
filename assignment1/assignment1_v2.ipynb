{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "for l in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    allRatings.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsTrain = allRatings[:190000]\n",
    "ratingsValid = allRatings[190000:]\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "for u,b,r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))\n",
    "\n",
    "small_ratingsValid = ratingsValid[:len(ratingsValid) // 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    return len(s1.intersection(s2)) / len(s1.union(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "allbooks = set()\n",
    "for user in ratingsPerUser:\n",
    "    for book, _ in ratingsPerUser[user]:\n",
    "        allbooks.add(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsValidBinary = [(user, book, 1) for user, book, _ in ratingsValid]\n",
    "for user, book, _ in ratingsValid:\n",
    "    newBook = random.choice(list(allbooks))\n",
    "    while newBook in ratingsPerUser[user]:\n",
    "        newBook = random.choice(list(allbooks))\n",
    "    ratingsValidBinary.append((user, newBook, 0))\n",
    "\n",
    "# ratingsValidBinary = [(user, book, 1) for user, book, _ in small_ratingsValid]\n",
    "\n",
    "# for user, book, _ in small_ratingsValid:\n",
    "#     newBook = random.choice(list(allbooks))\n",
    "#     while newBook in [b for b, _ in ratingsPerUser[user]]:\n",
    "#         newBook = random.choice(list(allbooks))\n",
    "#     ratingsValidBinary.append((user, newBook, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsTrainBinary = [(user, book, 1) for user, book, _ in ratingsTrain]\n",
    "for user, book, _ in ratingsTrain:\n",
    "    newBook = random.choice(list(allbooks))\n",
    "    while newBook in ratingsPerUser[user]:\n",
    "        newBook = random.choice(list(allbooks))\n",
    "    ratingsTrainBinary.append((user, newBook, 0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.725\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Calculate max popularity once\n",
    "bookCount = defaultdict(int)\n",
    "for user in ratingsPerUser:\n",
    "    for book, _ in ratingsPerUser[user]:\n",
    "        bookCount[book] += 1\n",
    "#max_popularity = max(len(ratingsPerUser[u]) for u in ratingsPerUser)\n",
    "\n",
    "def extract_features(user, book):\n",
    "    users_for_book = set(u for u, _ in ratingsPerItem[book])\n",
    "    bprime = set(b for b, _ in ratingsPerUser[user] if b != book)\n",
    "    \n",
    "    max_jaccard = max(Jaccard(set(u for u, _ in ratingsPerItem[b]), users_for_book) for b in bprime) if bprime else 0\n",
    "    popularity_score = np.log1p(bookCount[book])\n",
    "    \n",
    "    return [max_jaccard, popularity_score]\n",
    "\n",
    "# def extract_features(user, book):\n",
    "#     books_for_user = set(b for b, _ in ratingsPerUser[user])\n",
    "#     uprime = set(u for u, _ in ratingsPerItem[book] if u != user)\n",
    "    \n",
    "#     max_jaccard = max(Jaccard(set(b for b, _ in ratingsPerUser[u]), books_for_user) for u in uprime) if uprime else 0\n",
    "#     popularity_score = len(books_for_user) / max_popularity\n",
    "    \n",
    "#     return [max_jaccard, popularity_score]\n",
    "# Extract features and labels for training set\n",
    "features = [extract_features(user, book) for user, book, _ in ratingsTrainBinary]\n",
    "labels = [predict for _, _, predict in ratingsTrainBinary]\n",
    "\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "clf.fit(features, labels)\n",
    "\n",
    "\n",
    "features_valid = [extract_features(user, book) for user, book, _ in ratingsValidBinary]\n",
    "labels_valid = [predict for _, _, predict in ratingsValidBinary]\n",
    "\n",
    "\n",
    "features_valid = np.array(features_valid)\n",
    "labels_valid = np.array(labels_valid)\n",
    "\n",
    "features_valid = scaler.transform(features_valid)\n",
    "\n",
    "predictions = clf.predict(features_valid)\n",
    "accuracy = accuracy_score(labels_valid, predictions)\n",
    "print(\"Validation Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive jaccard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def solve(thresh1):\n",
    "#     ans = {}\n",
    "#     for user, book, _ in ratingsValidBinary:\n",
    "#         users_for_book = set(u for u, _ in ratingsPerItem[book])\n",
    "#         bprime = set(b for b, _ in ratingsPerUser[user] if b != book)\n",
    "        \n",
    "#         max_jaccard = 0\n",
    "#         for b in bprime:\n",
    "#             jaccard = Jaccard(set(u for u, _ in ratingsPerItem[b]), users_for_book)\n",
    "#             max_jaccard = max(max_jaccard, jaccard)\n",
    "        \n",
    "#         ans[(user, book)] = 1 if max_jaccard > thresh1 else 0\n",
    "\n",
    "#     correct = sum(1 for user, book, r in ratingsValidBinary if ans.get((user, book)) == r)\n",
    "#     accuracy = correct / len(ratingsValidBinary) if ratingsValidBinary else 0\n",
    "#     return accuracy\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69855"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solve(0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weighted jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_books = set() \n",
    "# def solve(alpha, combined_thresh):\n",
    "#     read_books.clear()\n",
    "#     max_popularity = max(len(ratingsPerItem[b]) for b in ratingsPerItem)\n",
    "\n",
    "#     for user, book, _ in ratingsValidBinary:\n",
    "#         users_for_book = set(u for u, _ in ratingsPerItem[book])\n",
    "#         bprime = set(b for b, _ in ratingsPerUser[user] if b != book)\n",
    "        \n",
    "#         max_jaccard = 0\n",
    "#         for b in bprime:\n",
    "#             jaccard = Jaccard(set(u for u, _ in ratingsPerItem[b]), users_for_book)\n",
    "#             max_jaccard = max(max_jaccard, jaccard)\n",
    "             \n",
    "#         popularity_score = len(users_for_book) / max_popularity\n",
    "#         if(len(users_for_book) > 50):\n",
    "#             read_books.add(book)\n",
    "#             continue\n",
    "#         combined_score = alpha * max_jaccard + (1 - alpha) * popularity_score\n",
    "#         if combined_score > combined_thresh:\n",
    "#             read_books.add(book) \n",
    "\n",
    "#     correct = 0\n",
    "#     for _, book, predict in ratingsValidBinary:\n",
    "#         correct += (predict == 1 and book in read_books) or (predict == 0 and book not in read_books)\n",
    "    \n",
    "#     acc = correct / len(ratingsValidBinary)\n",
    "#     return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimal Alpha Threshold: 0.55, Optimal Combined Threshold: 0.02, Best Accuracy: 0.75725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7494\n"
     ]
    }
   ],
   "source": [
    "print(solve(0.1, 0.032))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Threshold: 0.5, Combined Threshold: 0.02, Accuracy: 0.738\n",
      "Alpha Threshold: 0.5, Combined Threshold: 0.021, Accuracy: 0.739\n",
      "Alpha Threshold: 0.5, Combined Threshold: 0.022000000000000002, Accuracy: 0.7413\n",
      "Alpha Threshold: 0.5, Combined Threshold: 0.023000000000000003, Accuracy: 0.742\n",
      "Alpha Threshold: 0.51, Combined Threshold: 0.02, Accuracy: 0.7385\n",
      "Alpha Threshold: 0.51, Combined Threshold: 0.021, Accuracy: 0.7394\n",
      "Alpha Threshold: 0.51, Combined Threshold: 0.022000000000000002, Accuracy: 0.74075\n",
      "Alpha Threshold: 0.51, Combined Threshold: 0.023000000000000003, Accuracy: 0.7416\n",
      "Alpha Threshold: 0.52, Combined Threshold: 0.02, Accuracy: 0.73855\n",
      "Alpha Threshold: 0.52, Combined Threshold: 0.021, Accuracy: 0.73925\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[140], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m alpha_range \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.56\u001b[39m, \u001b[38;5;241m0.01\u001b[39m) \n\u001b[0;32m     18\u001b[0m combined_range \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0.02\u001b[39m, \u001b[38;5;241m0.024\u001b[39m, \u001b[38;5;241m0.001\u001b[39m) \n\u001b[1;32m---> 20\u001b[0m best_alpha_thresh, best_combined_thresh, best_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mgs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_range\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimal Alpha Threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_alpha_thresh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Optimal Combined Threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_combined_thresh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Best Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[140], line 8\u001b[0m, in \u001b[0;36mgs\u001b[1;34m(alpha_range, combined_range)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m alpha_thresh \u001b[38;5;129;01min\u001b[39;00m alpha_range:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m combined_thresh \u001b[38;5;129;01min\u001b[39;00m combined_range:\n\u001b[1;32m----> 8\u001b[0m         accuracy \u001b[38;5;241m=\u001b[39m \u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43malpha_thresh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_thresh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlpha Threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malpha_thresh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Combined Threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcombined_thresh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m accuracy \u001b[38;5;241m>\u001b[39m best_accuracy:\n",
      "Cell \u001b[1;32mIn[134], line 12\u001b[0m, in \u001b[0;36msolve\u001b[1;34m(alpha, combined_thresh)\u001b[0m\n\u001b[0;32m     10\u001b[0m max_jaccard \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bprime:\n\u001b[1;32m---> 12\u001b[0m     jaccard \u001b[38;5;241m=\u001b[39m Jaccard(\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mratingsPerItem\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, users_for_book)\n\u001b[0;32m     13\u001b[0m     max_jaccard \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(max_jaccard, jaccard)\n\u001b[0;32m     15\u001b[0m popularity_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(users_for_book) \u001b[38;5;241m/\u001b[39m max_popularity\n",
      "Cell \u001b[1;32mIn[134], line 12\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     10\u001b[0m max_jaccard \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bprime:\n\u001b[1;32m---> 12\u001b[0m     jaccard \u001b[38;5;241m=\u001b[39m Jaccard(\u001b[38;5;28mset\u001b[39m(u \u001b[38;5;28;01mfor\u001b[39;00m u, _ \u001b[38;5;129;01min\u001b[39;00m ratingsPerItem[b]), users_for_book)\n\u001b[0;32m     13\u001b[0m     max_jaccard \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(max_jaccard, jaccard)\n\u001b[0;32m     15\u001b[0m popularity_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(users_for_book) \u001b[38;5;241m/\u001b[39m max_popularity\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def gs(alpha_range, combined_range):\n",
    "    best_accuracy = 0\n",
    "    best_alpha_thresh = None\n",
    "    best_combined_thresh = None\n",
    "    for alpha_thresh in alpha_range:\n",
    "        for combined_thresh in combined_range:\n",
    "            accuracy = solve(alpha_thresh, combined_thresh)\n",
    "            print(f\"Alpha Threshold: {alpha_thresh}, Combined Threshold: {combined_thresh}, Accuracy: {accuracy}\")\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_alpha_thresh = alpha_thresh\n",
    "                best_combined_thresh = combined_thresh\n",
    "\n",
    "    return best_alpha_thresh, best_combined_thresh, best_accuracy\n",
    "\n",
    "alpha_range = np.arange(0.5, 0.56, 0.01) \n",
    "combined_range = np.arange(0.02, 0.024, 0.001) \n",
    "\n",
    "best_alpha_thresh, best_combined_thresh, best_accuracy = gs(\n",
    "    alpha_range, combined_range\n",
    ")\n",
    "print(f\"Optimal Alpha Threshold: {best_alpha_thresh}, Optimal Combined Threshold: {best_combined_thresh}, Best Accuracy: {best_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimal Alpha Threshold: 0.535, Optimal Combined Threshold: 0.022000000000000002, Best Accuracy: 0.7595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Read.csv\", 'w')\n",
    "for l in open(\"pairs_Read.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split(',')\n",
    "    if b in ret:\n",
    "        predictions.write(u + ',' + b + \",1\\n\")\n",
    "    else:\n",
    "        predictions.write(u + ',' + b + \",0\\n\")\n",
    "\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.mean([r for _, _, r in ratingsTrain])\n",
    "beta_user = defaultdict(float)\n",
    "beta_book = defaultdict(float)\n",
    "\n",
    "def solve(lambda_reg):\n",
    "    for _ in range(100):\n",
    "        alpha = sum(rating - (beta_user[user] + beta_book[book]) for user, book, rating in ratingsTrain) / len(ratingsTrain)\n",
    "        for user, items in ratingsPerUser.items():\n",
    "            beta_user[user] = sum(rating - (alpha + beta_book[book]) for book, rating in items) / (lambda_reg + len(items))\n",
    "        for book, items in ratingsPerItem.items():\n",
    "            beta_book[book] = sum(rating - (alpha + beta_user[user]) for user, rating in items) / (lambda_reg + len(items))\n",
    "\n",
    "    valid_error = [(rating - (alpha + beta_user.get(user, 0) + beta_book.get(book, 0))) ** 2 for user, book, rating in ratingsValid]\n",
    "    validMSE = np.mean(valid_error).item()\n",
    "    return validMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.342360167360211 1.4106621594632809"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.333333333333336 66.66666666666666\n",
      "22.222222222222218 44.44444444444444\n",
      "14.814814814814815 29.629629629629626\n",
      "9.876543209876543 19.75308641975308\n",
      "6.584362139917694 13.168724279835388\n",
      "4.38957475994513 8.779149519890257\n",
      "2.9263831732967525 5.852766346593505\n",
      "4.8773052888279205 6.828227404359089\n",
      "4.226997916984198 5.527612660671644\n",
      "3.793459669088383 4.660536164880013\n",
      "4.371510666282803 4.9495616634772235\n",
      "4.17882700055133 4.564194332014276\n",
      "4.050371223397014 4.307282777705645\n",
      "4.221645592936102 4.3929199624751885\n",
      "4.3358285059621595 4.450011418988218\n",
      "4.297767534953474 4.373889476970846\n",
      "4.348515496298389 4.399263457643303\n",
      "4.331599509183417 4.36543148341336\n",
      "4.320322184440102 4.342876833926732\n",
      "4.335358617431188 4.350395050422274\n",
      "4.3303464731008265 4.34037076176155\n",
      "4.337029332207976 4.343712191315125\n"
     ]
    }
   ],
   "source": [
    "l, r, eps = 0, 100, 1e-4\n",
    "\n",
    "while(r-l > eps):\n",
    "    m1 = l + (r-l)/3\n",
    "    m2 = r - (r-l)/3\n",
    "    print(m1, m2)\n",
    "    if solve(m1) < solve(m2):\n",
    "        r = m2\n",
    "    else:\n",
    "        l = m1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4101458695454359\n"
     ]
    }
   ],
   "source": [
    "print(solve(4.340628291032128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Rating.csv\", 'w')\n",
    "for l in open(\"pairs_Rating.csv\"):\n",
    "    if l.startswith(\"userID\"): # header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split(',') # Read the user and item from the \"pairs\" file and write out your prediction\n",
    "    prediction = alpha + beta_user.get(u, 0) + beta_book.get(b, 0)\n",
    "    predictions.write(u + ',' + b + ',' + str(prediction) + '\\n')\n",
    "    \n",
    "predictions.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
