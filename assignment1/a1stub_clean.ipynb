{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f55c023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\College_UCSD\\CY4\\Q1\\CSE158\\A1\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "from sklearn import linear_model\n",
    "import statistics\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "005c1a02-c5bf-4241-8d00-dc260d36f08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb2abe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e54fa48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJSON(path):\n",
    "    f = gzip.open(path, 'rt', encoding=\"utf-8\")\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        d = eval(l)\n",
    "        u = d['userID']\n",
    "        g = d['gameID']\n",
    "        yield u,g,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e72d24da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data structures that will be useful\n",
    "allHours = []\n",
    "usersPerGame = defaultdict(set)\n",
    "gamesPerUser = defaultdict(set)\n",
    "games = set()\n",
    "for l in readJSON(\"train.json.gz\"):\n",
    "    gamesPerUser[l[0]].add(l[1])\n",
    "    usersPerGame[l[1]].add(l[0])\n",
    "    allHours.append(l)\n",
    "    games.add(l[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameCountc = defaultdict(int)\n",
    "totalPlayedc = 0\n",
    "\n",
    "#REFACTOR THIS TO INCLUDE THE ENTIRE DATASET\n",
    "for user,game,_ in allHours:\n",
    "  gameCountc[game] += 1\n",
    "  totalPlayedc += 1\n",
    "mostPopularc = [(gameCountc[x], x) for x in gameCountc]\n",
    "mostPopularc.sort()\n",
    "mostPopularc.reverse()\n",
    "mostPopularc_nums = [i[0] for i in mostPopularc]\n",
    "\n",
    "usersPerGamec = defaultdict(set)\n",
    "gamesPerUserc = defaultdict(set)\n",
    "for u,g,_ in allHours:\n",
    "    gamesPerUserc[u].add(g)\n",
    "    usersPerGamec[g].add(u)\n",
    "\n",
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom\n",
    "\n",
    "\n",
    "def get_popularity_percentile_c(g):\n",
    "    counter = 0\n",
    "    for i in mostPopularc:\n",
    "        if i[1] == g:\n",
    "            return 1 - (counter/len(mostPopularc))\n",
    "        counter += 1\n",
    "    #case where game does not appear, TODO\n",
    "    return 0\n",
    "\n",
    "def mean_item_jaccard_c(u,g):\n",
    "    jlist = [Jaccard(usersPerGamec[g],usersPerGamec[gc],) for gc in list(gamesPerUserc[u]) if g!=gc]\n",
    "    if len(jlist) == 0:\n",
    "        return False\n",
    "    return sum(jlist)/len(jlist)\n",
    "\n",
    "def max_item_jaccard_c(u,g):\n",
    "    return max([Jaccard(usersPerGamec[g],usersPerGamec[gc],) for gc in list(gamesPerUserc[u]) if g!=gc], default=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfcf2295-aefc-4542-a3b4-26028c69038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pairs_Played():\n",
    "    test = []\n",
    "    print(test)\n",
    "    for l in open(\"pairs_Played.csv\"):\n",
    "        if l.startswith(\"userID\"):\n",
    "            continue\n",
    "        u,g = l.strip().split(',')\n",
    "        test.append((u,g,0))\n",
    "    return test\n",
    "\n",
    "def write_pairs_Played(predictions):\n",
    "    predictions_f = open(\"predictions_Played.csv\", 'w')\n",
    "    predictions_f.write(\"userID,gameID,prediction\\n\")\n",
    "    for u,g,n in predictions:\n",
    "        predictions_f.write(u + ',' + g + ',' + str(n) + '\\n')\n",
    "    predictions_f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "userIDs = {}\n",
    "itemIDs = {}\n",
    "interactions = []\n",
    "playedSet = set()\n",
    "\n",
    "userSet = set()\n",
    "gameSet = set()\n",
    "\n",
    "for u,i,r in allHours: #change to trainHours if necess\n",
    "    if not u in userIDs: userIDs[u] = len(userIDs)\n",
    "    if not i in itemIDs: itemIDs[i] = len(itemIDs)\n",
    "    interactions.append((u,i,r))\n",
    "\n",
    "\n",
    "nUsers,nItems = len(userIDs),len(itemIDs)\n",
    "\n",
    "itemsPerUser = defaultdict(list)\n",
    "usersPerItem = defaultdict(list)\n",
    "for u,i,r in interactions:\n",
    "    itemsPerUser[u].append(i)\n",
    "    usersPerItem[i].append(u)\n",
    "\n",
    "items = list(itemIDs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10, objective = 0.50948447\n",
      "iteration 20, objective = 0.47556764\n",
      "iteration 30, objective = 0.46087337\n",
      "iteration 40, objective = 0.4517896\n",
      "iteration 50, objective = 0.44577694\n",
      "iteration 60, objective = 0.442838\n",
      "iteration 70, objective = 0.44014913\n",
      "iteration 80, objective = 0.43844894\n",
      "iteration 90, objective = 0.4385128\n",
      "iteration 100, objective = 0.435513\n",
      "iteration 110, objective = 0.43550178\n",
      "iteration 120, objective = 0.43578362\n",
      "iteration 130, objective = 0.43905908\n",
      "iteration 140, objective = 0.4399476\n",
      "iteration 150, objective = 0.43526947\n",
      "iteration 160, objective = 0.44063962\n",
      "iteration 170, objective = 0.4359154\n",
      "iteration 180, objective = 0.43638206\n",
      "iteration 190, objective = 0.43580627\n",
      "iteration 200, objective = 0.4378103\n",
      "iteration 210, objective = 0.43456268\n",
      "iteration 220, objective = 0.43524468\n",
      "iteration 230, objective = 0.43359262\n",
      "iteration 240, objective = 0.43716258\n",
      "iteration 250, objective = 0.4337182\n",
      "iteration 260, objective = 0.43599638\n",
      "iteration 270, objective = 0.43469632\n",
      "iteration 280, objective = 0.43531972\n",
      "iteration 290, objective = 0.43596795\n",
      "iteration 300, objective = 0.43395245\n",
      "iteration 310, objective = 0.43550208\n",
      "iteration 320, objective = 0.43197542\n",
      "iteration 330, objective = 0.43470126\n",
      "iteration 340, objective = 0.43477476\n",
      "iteration 350, objective = 0.4348056\n",
      "iteration 360, objective = 0.43374074\n",
      "iteration 370, objective = 0.43365496\n",
      "iteration 380, objective = 0.43656406\n",
      "iteration 390, objective = 0.43340042\n",
      "iteration 400, objective = 0.43557405\n",
      "iteration 410, objective = 0.43583176\n",
      "iteration 420, objective = 0.43610284\n",
      "iteration 430, objective = 0.43791315\n",
      "iteration 440, objective = 0.43483818\n",
      "iteration 450, objective = 0.43561912\n",
      "iteration 460, objective = 0.4328982\n",
      "iteration 470, objective = 0.43618423\n",
      "iteration 480, objective = 0.43320212\n",
      "iteration 490, objective = 0.4338672\n",
      "iteration 500, objective = 0.43342066\n",
      "iteration 510, objective = 0.4342647\n",
      "iteration 520, objective = 0.43393835\n",
      "iteration 530, objective = 0.43207702\n",
      "iteration 540, objective = 0.43527216\n",
      "iteration 550, objective = 0.43438563\n",
      "iteration 560, objective = 0.43465808\n",
      "iteration 570, objective = 0.43570483\n",
      "iteration 580, objective = 0.43541986\n",
      "iteration 590, objective = 0.434504\n",
      "iteration 600, objective = 0.43674105\n",
      "iteration 610, objective = 0.43695766\n",
      "iteration 620, objective = 0.43597668\n",
      "iteration 630, objective = 0.4368239\n",
      "iteration 640, objective = 0.43547818\n",
      "iteration 650, objective = 0.43484673\n",
      "iteration 660, objective = 0.43317363\n",
      "iteration 670, objective = 0.436518\n",
      "iteration 680, objective = 0.43459627\n",
      "iteration 690, objective = 0.4330083\n",
      "iteration 700, objective = 0.43530262\n",
      "iteration 710, objective = 0.43404722\n",
      "iteration 720, objective = 0.4342839\n",
      "iteration 730, objective = 0.43590972\n",
      "iteration 740, objective = 0.4361263\n",
      "iteration 750, objective = 0.4357108\n",
      "iteration 760, objective = 0.4363821\n",
      "iteration 770, objective = 0.43514097\n",
      "iteration 780, objective = 0.43513888\n",
      "iteration 790, objective = 0.43209833\n",
      "iteration 800, objective = 0.4318881\n"
     ]
    }
   ],
   "source": [
    "class BPRbatch(tf.keras.Model):\n",
    "    def __init__(self, K, lambI, lambG):\n",
    "        super(BPRbatch, self).__init__()\n",
    "        # Initialize variables\n",
    "        self.betaI = tf.Variable(tf.random.normal([len(itemIDs)],stddev=0.001))\n",
    "        self.gammaU = tf.Variable(tf.random.normal([len(userIDs),K],stddev=0.001))\n",
    "        self.gammaI = tf.Variable(tf.random.normal([len(itemIDs),K],stddev=0.001))\n",
    "        # Regularization coefficient\n",
    "        self.lambI = lambI\n",
    "        self.lambG = lambG\n",
    "        \n",
    "    # Prediction for a single instance\n",
    "    def predict(self, u, i):\n",
    "        p = self.betaI[i] + tf.tensordot(self.gammaU[u], self.gammaI[i], 1)\n",
    "        return p\n",
    "\n",
    "    # Regularizer\n",
    "    def reg(self):\n",
    "        return (self.lambI * (tf.nn.l2_loss(self.betaI))) + (self.lambG * (tf.nn.l2_loss(self.gammaU))) +  (self.lambG * tf.nn.l2_loss(self.gammaI))\n",
    "\n",
    "    \n",
    "    def score(self, sampleU, sampleI):\n",
    "        u = tf.convert_to_tensor(sampleU, dtype=tf.int32)\n",
    "        i = tf.convert_to_tensor(sampleI, dtype=tf.int32)\n",
    "        beta_i = tf.nn.embedding_lookup(self.betaI, i)\n",
    "        gamma_u = tf.nn.embedding_lookup(self.gammaU, u)\n",
    "        gamma_i = tf.nn.embedding_lookup(self.gammaI, i)\n",
    "        x_ui = beta_i + tf.reduce_sum(tf.multiply(gamma_u, gamma_i), 1)\n",
    "        return x_ui\n",
    "\n",
    "    def call(self, sampleU, sampleI, sampleJ):\n",
    "        x_ui = self.score(sampleU, sampleI)\n",
    "        x_uj = self.score(sampleU, sampleJ)\n",
    "        return -tf.reduce_mean(tf.math.log(tf.math.sigmoid(x_ui - x_uj)))\n",
    "\n",
    "\n",
    "\n",
    "def trainingStepBPR(model, interactions):\n",
    "    Nsamples = 150000\n",
    "    with tf.GradientTape() as tape:\n",
    "        sampleU, sampleI, sampleJ = [], [], []\n",
    "        for _ in range(Nsamples):\n",
    "            u,i,_ = random.choice(interactions) # positive sample\n",
    "            j = random.choice(items) # negative sample\n",
    "            while j in itemsPerUser[u]:\n",
    "                j = random.choice(items)\n",
    "            sampleU.append(userIDs[u])\n",
    "            sampleI.append(itemIDs[i])\n",
    "            sampleJ.append(itemIDs[j])\n",
    "\n",
    "        loss = model(sampleU,sampleI,sampleJ)\n",
    "        loss += model.reg()\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients((grad, var) for\n",
    "                              (grad, var) in zip(gradients, model.trainable_variables)\n",
    "                              if grad is not None)\n",
    "    return loss.numpy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.1)\n",
    "modelBPR = BPRbatch(5, 0.00001, 0.00001)\n",
    "for i in range(800):\n",
    "    if i == 400:\n",
    "        optimizer.learning_rate = 0.00001\n",
    "    obj = trainingStepBPR(modelBPR, interactions)\n",
    "\n",
    "    if (i % 10 == 9): print(\"iteration \" + str(i+1) + \", objective = \" + str(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "all_copy = copy.deepcopy(allHours)\n",
    "random.shuffle(all_copy)\n",
    "logr_training = []\n",
    "\n",
    "for u,g,_ in all_copy[:50000]:\n",
    "    logr_training.append((u,g,1))\n",
    "    while True:\n",
    "        zg = random.choice(tuple(games))\n",
    "        if not zg in gamesPerUser[u]:\n",
    "            break\n",
    "    logr_training.append((u,zg,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_bprp(u,g,modelBPR):\n",
    "    try: \n",
    "        return [1] + [modelBPR.predict(userIDs[u], itemIDs[g]).numpy()] + [get_popularity_percentile_c(g)]\n",
    "    except KeyError:\n",
    "        return [1] + [0.6] + [max_item_jaccard_c(u,g)]\n",
    "\n",
    "\n",
    "def pipeline(reg, XT, XP, training_set):\n",
    "    y = [r for _,_,r in training_set]\n",
    "    mod = linear_model.LogisticRegression(C=reg, class_weight='balanced')\n",
    "    mod.fit(XT,y)\n",
    "    y_pred = mod.predict(XP)\n",
    "    return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bprp = [feat_bprp(u,g, modelBPR) for u,g,_ in logr_training]\n",
    "y_bprp = [r for _,_,r in logr_training]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "test_set = read_pairs_Played()\n",
    "\n",
    "mod = linear_model.LogisticRegression(C=0.0001, class_weight='balanced')\n",
    "mod.fit(X_bprp, y_bprp)\n",
    "\n",
    "test_predictions = []\n",
    "for u,g,_ in test_set:\n",
    "    try:\n",
    "        f = [1] + [modelBPR.predict(userIDs[u], itemIDs[g]).numpy()] + [get_popularity_percentile_c(g)]\n",
    "    except KeyError:\n",
    "        f = [1] + [0.22] + [get_popularity_percentile_c(g)]\n",
    "    test_predictions.append((u, g, mod.predict([f])[0]))\n",
    "\n",
    "write_pairs_Played(test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c82a7a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Hours played prediction                        #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ced4bf80-22e7-44eb-9efe-e2ec42f893bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "globalAverage = sum([r[\"hours_transformed\"] for u,g,r in allHours])/(len(allHours))\n",
    "ug_review = {}\n",
    "for u,g,r in allHours:\n",
    "    ug_review[(u,g)] = r['hours_transformed']\n",
    "hours = [(u,g,r['hours_transformed']) for u,g,r in allHours]\n",
    "\n",
    "def iterate2(lambU,lambI,betaU,betaI,alpha,hoursList,hyperp):\n",
    "\n",
    "    mse_i = MSE([(alpha + betaU[u] + betaI[g]) for u,g,r in hoursList], [r for _,_,r in hoursList])\n",
    "    #prev = mse_i\n",
    "    \n",
    "    d = 1\n",
    "    while d <= hyperp:\n",
    "        alpha_t = 0\n",
    "        betaU_t = defaultdict(lambda: 0)\n",
    "        betaI_t = defaultdict(lambda: 0)\n",
    "        for u,g,r in hoursList:\n",
    "            alpha_t += r - (betaU[u] + betaI[g])\n",
    "\n",
    "        alpha = alpha_t/len(hoursList)\n",
    "\n",
    "        for u in betaU:\n",
    "            sum_u = 0\n",
    "            for i in gamesPerUser[u]:\n",
    "                sum_u += ug_review[u,i] - (alpha + betaI[i])\n",
    "            sum_u = sum_u/(lambU + len(gamesPerUser[u]))\n",
    "            betaU_t[u] = sum_u\n",
    "\n",
    "        betaU = betaU_t\n",
    "\n",
    "        for i in betaI:\n",
    "            sum_i = 0\n",
    "            for u in usersPerGame[i]:\n",
    "                sum_i += ug_review[u,i] - (alpha + betaU[u])\n",
    "            sum_i = sum_i/(lambI + len(usersPerGame[i]))\n",
    "            betaI_t[i] = sum_i\n",
    "        \n",
    "        betaI = betaI_t\n",
    "\n",
    "        mse_i = MSE([(alpha + betaU[u] + betaI[g]) for u,g,r in hoursList], [r for _,_,r in hoursList])  \n",
    "\n",
    "        #d = abs(mse_i - prev)\n",
    "        d += 1\n",
    "        #print(d)\n",
    "        #prev = mse_i\n",
    "        #print(mse_i)\n",
    "    return alpha, betaU, betaI        \n",
    "\n",
    "def MSE(y, ypred):\n",
    "    differences = [(x-y)**2 for x,y in zip(ypred,y)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa01029d-a130-4389-9f0c-bf18fb3726f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7905799620497387\n"
     ]
    }
   ],
   "source": [
    "betaU = defaultdict(lambda: 0)\n",
    "betaI = defaultdict(lambda: 0)\n",
    "\n",
    "alpha = globalAverage \n",
    "\n",
    "alpha = globalAverage \n",
    "alpha, betaU, betaI = iterate2(8,3, betaU, betaI, alpha, hours, 400)\n",
    "validMSE = MSE([(alpha + betaU[u] + betaI[g]) for u,g,_ in hours], [r for _,_,r in hours])\n",
    "print(validMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15981388-f720-4cc1-a597-ab614ea89b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pairs_Hours():\n",
    "    test = []\n",
    "    print(test)\n",
    "    for l in open(\"pairs_Hours.csv\"):\n",
    "        if l.startswith(\"userID\"):\n",
    "            continue\n",
    "        u,g = l.strip().split(',')\n",
    "        test.append((u,g,0))\n",
    "    return test\n",
    "\n",
    "def write_pairs_Hours(predictions):\n",
    "    predictions_f = open(\"predictions_Hours.csv\", 'w')\n",
    "    predictions_f.write(\"userID,gameID,prediction\\n\")\n",
    "    for u,g,n in predictions:\n",
    "        predictions_f.write(u + ',' + g + ',' + str(n) + '\\n')\n",
    "    predictions_f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d54d04fc-34af-4be9-8472-8e3b5fde49d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "test = read_pairs_Hours()\n",
    "pred_would = [(u,g,(alpha + betaU[u] + betaI[g])) for u,g,r in test]\n",
    "write_pairs_Hours(pred_would)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
